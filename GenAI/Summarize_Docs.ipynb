{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMh5X44qJ45z8QTXWt7XV7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherry-ger/elastic-workshop/blob/main/GenAI/Summarize_Docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages and libraries we will need for the workshop"
      ],
      "metadata": {
        "id": "9o7nDx8D1r_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uF4KUQahJxg"
      },
      "outputs": [],
      "source": [
        "# install packages\n",
        "!pip install -qU langchain elasticsearch tiktoken\n",
        "!pip install transformers\n",
        "!pip install accelerate bitsandbytes\n",
        "!pip install sentencepiece\n",
        "\n",
        "# import modules\n",
        "from getpass import getpass\n",
        "from langchain.vectorstores import ElasticsearchStore\n",
        "from urllib.request import urlopen\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import json\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Set Up"
      ],
      "metadata": {
        "id": "YxbPvphl1_ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set elastic cloud id and password\n",
        "\n",
        "CLOUD_ID = getpass(\"Elastic deployment Cloud ID\")\n",
        "CLOUD_USERNAME = \"elastic\"\n",
        "CLOUD_PASSWORD = getpass(\"Elastic deployment Password\")"
      ],
      "metadata": {
        "id": "FFAukA3ork-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "Here is the [JSON file](https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/workplace-search/data/data.json)"
      ],
      "metadata": {
        "id": "Dci7jdRj2oKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/workplace-search/data/data.json\"\n",
        "\n",
        "response = urlopen(url)\n",
        "\n",
        "workplace_docs = json.loads(response.read())"
      ],
      "metadata": {
        "id": "tYesWh1qs2EQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data and Chunking with LangChain Text Splitters\n",
        "\n",
        "Here is the [documentation](https://js.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/token).\n",
        "\n"
      ],
      "metadata": {
        "id": "JkcWpA3O4u7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = []\n",
        "content = []\n",
        "\n",
        "# Add metadata to our documents\n",
        "\n",
        "for doc in workplace_docs:\n",
        "  content.append(doc[\"content\"])\n",
        "  metadata.append({\n",
        "      \"name\": doc[\"name\"],\n",
        "      \"summary\": doc[\"summary\"],\n",
        "      \"rolePermissions\":doc[\"rolePermissions\"]\n",
        "  })\n",
        "\n",
        "# Chunking using fixed length chunking method\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=384, chunk_overlap=20)\n",
        "docs = text_splitter.create_documents(content, metadatas=metadata)\n",
        "\n",
        "for documents in docs:\n",
        "  print(documents.page_content)\n",
        "  print(documents.metadata['name'])\n",
        "  print(documents.metadata['summary'])\n",
        "  print(documents.metadata['rolePermissions'])\n"
      ],
      "metadata": {
        "id": "8y9rUH5WsjOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Elasticsearch using Python client"
      ],
      "metadata": {
        "id": "YUq3NU143oZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "client = Elasticsearch(\n",
        "    cloud_id=CLOUD_ID,\n",
        "    basic_auth=(\"elastic\", CLOUD_PASSWORD),\n",
        "    request_timeout=30\n",
        ")\n",
        "\n",
        "# Successful response!\n",
        "client.info()"
      ],
      "metadata": {
        "id": "pwIYbidA0yNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Start ELSER model"
      ],
      "metadata": {
        "id": "FVVDf4nz3xw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download / Load ELSER\n",
        "client.ml.put_trained_model(model_id=\".elser_model_1\", input={\"field_names\": \"text_field\"})\n"
      ],
      "metadata": {
        "id": "rqCGtLzQ0NVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start ELSER\n",
        "client.ml.start_trained_model_deployment(\n",
        "    model_id=\".elser_model_1\"\n",
        ")"
      ],
      "metadata": {
        "id": "Hmi0_UN95P5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingest data using LangChain"
      ],
      "metadata": {
        "id": "kCKXxvqi3TNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = ElasticsearchStore(es_connection=client,\n",
        "            index_name= \"workplace_index\"\n",
        "        )\n",
        "\n",
        "# Ingest using ELSER - sparse encoder strategy\n",
        "documents = vector_store.from_documents(\n",
        "    docs, es_connection=client, index_name=\"workplace_index\",\n",
        "    strategy=ElasticsearchStore.SparseVectorRetrievalStrategy()\n",
        ")"
      ],
      "metadata": {
        "id": "3JZE2UeMs-ch"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query with LangChain"
      ],
      "metadata": {
        "id": "DHIcAI2KEy0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper method to print out outputs\n",
        "def showResults(output):\n",
        "  print(\"Total results: \", len(output))\n",
        "  for index in range(len(output)):\n",
        "    print(output[index])\n"
      ],
      "metadata": {
        "id": "yuY3BDlYuMkP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = documents.similarity_search(\"How does the compensation work?\")\n",
        "showResults(results)"
      ],
      "metadata": {
        "id": "WB2a5oAnuUL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Expansion query with ELSER\n",
        "\n",
        "Since we have splitted a single document into multiple pieces, we want to group the results of a single document into a single output by using the [Elasticsearch query results collapse](https://www.elastic.co/guide/en/elasticsearch/reference/current/collapse-search-results.html)."
      ],
      "metadata": {
        "id": "GGcjvvUaFSSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = input(\"Enter a question :\")\n",
        "print('\\n')\n",
        "# How does compensation work\n",
        "query={\n",
        "    \"text_expansion\": {\n",
        "    \"vector.tokens\": {\n",
        "        \"model_id\":\".elser_model_1\",\n",
        "        \"model_text\": query_text\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# print(query)\n",
        "\n",
        "# We don't want to repeatedly see the different sections of the same document\n",
        "# Let's just get all the sections and group them together by document name\n",
        "# Well at least the first 10 chunks\n",
        "\n",
        "collapse={\n",
        "    \"field\": \"metadata.name.keyword\",\n",
        "    \"inner_hits\": [{\n",
        "        \"name\": \"text\",\n",
        "        \"_source\": \"false\",\n",
        "        \"fields\": [\"text\"],\n",
        "        \"size\": 10\n",
        "      }]\n",
        "}\n",
        "\n",
        "# print collapse\n",
        "\n",
        "resp = client.search(index=\"workplace_index\", query=query, collapse=collapse, source=[\"metadata.name\", \"metadata.summary\", \"text\"])\n",
        "\n",
        "# Test to see if we have all the docs\n",
        "# for hit in resp['hits']['hits']:\n",
        "#  doc_name = hit['_source']['metadata']['name']\n",
        "#  print(f\"\\nDocument Name: {doc_name}\")\n",
        "\n",
        "# Show the first doc. Default sort order is by _score\n",
        "hit = resp['hits']['hits'][0]\n",
        "doc_name = hit['_source']['metadata']['name']\n",
        "print(f\"Document Name: {doc_name}\\n\")\n",
        "\n",
        "doc_text = \"summarize: \"\n",
        "\n",
        "# Compile the inner hits (at max we have 10)\n",
        "for inner_hit in hit['inner_hits']['text']['hits']['hits']:\n",
        "  doc_text += ''.join(inner_hit['fields']['text'])\n",
        "#  print(inner_hit['fields']['text'])\n",
        "#  print(\"\\n\")\n",
        "\n",
        "print(doc_text)"
      ],
      "metadata": {
        "id": "r9zM14TocMFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization\n",
        "\n",
        "Use a [T5 model](https://https://colab.research.google.com/drive/18sGI2hylGPUIW3mRrTPjH1F6vxBEfxp-#scrollTo=jRKq4f2H4AA8&line=3&uniqifier=1) to perform summarization"
      ],
      "metadata": {
        "id": "jRKq4f2H4AA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
        "# Not sufficient memory to import fp16 model\n",
        "#model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\", torch_dtype=torch.float16)\n",
        "# Two questions will run out of memory\n",
        "#model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")"
      ],
      "metadata": {
        "id": "_dcbnhmp1VYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(doc_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids,\n",
        "                         min_length=20,\n",
        "                         max_new_tokens=600\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "mgO-GeeQ2s7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up"
      ],
      "metadata": {
        "id": "LLfRW1TIGRyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop ELSER model\n",
        "client.ml.stop_trained_model_deployment(\n",
        "    model_id=\".elser_model_1\",\n",
        "     force=True\n",
        ")"
      ],
      "metadata": {
        "id": "ljhoKi56DqBs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}